{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Setup\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "from fund_lens_etl.clients.fec import FECAPIClient\n",
    "from fund_lens_etl.extractors.fec import (\n",
    "    FECScheduleAExtractor,\n",
    "    FECCommitteeExtractor,\n",
    "    FECCandidateExtractor,\n",
    ")\n",
    "from fund_lens_etl.loaders.bronze import (\n",
    "    BronzeFECScheduleALoader,\n",
    "    BronzeFECCommitteeLoader,\n",
    "    BronzeFECCandidateLoader,\n",
    ")\n",
    "from fund_lens_etl.database import get_db_session\n",
    "from fund_lens_etl.config import USState\n",
    "\n",
    "print(\"✓ All imports successful\")\n",
    "print(\"\\nThis notebook will populate bronze layer with MD 2026 data:\")\n",
    "print(\"  1. Extract & Load ALL Committees\")\n",
    "print(\"  2. Extract & Load ALL Candidates\")\n",
    "print(\"  3. Extract & Load Contributions for a few committees\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Initialize\n",
    "client = FECAPIClient()\n",
    "committee_extractor = FECCommitteeExtractor(api_client=client)\n",
    "candidate_extractor = FECCandidateExtractor(api_client=client)\n",
    "schedule_a_extractor = FECScheduleAExtractor(api_client=client)\n",
    "\n",
    "committee_loader = BronzeFECCommitteeLoader()\n",
    "candidate_loader = BronzeFECCandidateLoader()\n",
    "schedule_a_loader = BronzeFECScheduleALoader()\n",
    "\n",
    "print(\"✓ All extractors and loaders initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Extract & Load ALL MD Committees\n",
    "print(\"=\"*60)\n",
    "print(\"STEP 1: Extract & Load ALL Maryland Committees (2026)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "committee_df = committee_extractor.extract(\n",
    "    state=USState.MD,\n",
    "    cycle=2026,\n",
    ")\n",
    "\n",
    "print(f\"\\nExtracted {len(committee_df)} committees\")\n",
    "\n",
    "with get_db_session() as session:\n",
    "    loaded = committee_loader.load(session, committee_df)\n",
    "    print(f\"✓ Loaded {loaded} committees to bronze_fec_committee\")\n",
    "\n",
    "print(\"\\nCommittee type breakdown:\")\n",
    "print(committee_df.groupby(\"committee_type\").size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Extract & Load ALL MD Candidates\n",
    "print(\"=\"*60)\n",
    "print(\"STEP 2: Extract & Load ALL Maryland Candidates (2026)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "candidate_df = candidate_extractor.extract(\n",
    "    state=USState.MD,\n",
    "    cycle=2026,\n",
    ")\n",
    "\n",
    "print(f\"\\nExtracted {len(candidate_df)} candidates\")\n",
    "\n",
    "with get_db_session() as session:\n",
    "    loaded = candidate_loader.load(session, candidate_df)\n",
    "    print(f\"✓ Loaded {loaded} candidates to bronze_fec_candidate\")\n",
    "\n",
    "print(\"\\nOffice breakdown:\")\n",
    "print(candidate_df.groupby(\"office\").size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Get MD Candidate Committees\n",
    "print(\"=\"*60)\n",
    "print(\"STEP 3: Get Maryland Candidate Committees\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "committees = schedule_a_extractor.get_candidate_committees(\n",
    "    state=USState.MD,\n",
    "    election_cycle=2026\n",
    ")\n",
    "\n",
    "print(f\"Found {len(committees)} MD candidate committees\")\n",
    "print(\"\\nSample:\")\n",
    "for i, comm in enumerate(committees[:5]):\n",
    "    print(f\"  {i+1}. {comm['committee_name']} ({comm['committee_id']}) - {comm['office']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Extract & Load Schedule A for First 3 Committees\n",
    "print(\"=\"*60)\n",
    "print(\"STEP 4: Extract & Load Contributions (First 3 Committees)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "total_loaded = 0\n",
    "\n",
    "for i, committee in enumerate(committees[:3]):\n",
    "    print(f\"\\n{i+1}. Processing: {committee['committee_name']}\")\n",
    "    print(f\"   Committee ID: {committee['committee_id']}\")\n",
    "\n",
    "    # Extract all pages for this committee\n",
    "    all_contributions = []\n",
    "\n",
    "    try:\n",
    "        for page_df, metadata in schedule_a_extractor.extract_schedule_a_pages(\n",
    "            committee_id=committee['committee_id'],\n",
    "            election_cycle=2026,\n",
    "            starting_page=1\n",
    "        ):\n",
    "            all_contributions.append(page_df)\n",
    "\n",
    "            # Show progress every 5 pages\n",
    "            if metadata['page'] % 5 == 0:\n",
    "                print(f\"   Page {metadata['page']}/{metadata['total_pages']}: \"\n",
    "                      f\"{len(all_contributions) * 100} records so far...\")\n",
    "\n",
    "            # Limit to first 500 records per committee for testing\n",
    "            if len(all_contributions) * 100 >= 500:\n",
    "                print(f\"   Reached 500 record limit for testing\")\n",
    "                break\n",
    "\n",
    "        if all_contributions:\n",
    "            # Combine all pages\n",
    "            contributions_df = pd.concat(all_contributions, ignore_index=True)\n",
    "            print(f\"   ✓ Extracted {len(contributions_df)} contributions\")\n",
    "\n",
    "            # Load to bronze\n",
    "            with get_db_session() as session:\n",
    "                loaded = schedule_a_loader.load(session, contributions_df)\n",
    "                total_loaded += loaded\n",
    "                print(f\"   ✓ Loaded {loaded} contributions to bronze_fec_schedule_a\")\n",
    "        else:\n",
    "            print(f\"   No contributions found\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"   ✗ Error: {e}\")\n",
    "        continue\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"TOTAL: Loaded {total_loaded} contributions across {i+1} committees\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6 (REVISED): Extract & Load Schedule A - Skip Empty Committees\n",
    "print(\"=\"*60)\n",
    "print(\"STEP 4: Extract & Load Contributions (First 3 with data)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "total_loaded = 0\n",
    "committees_processed = 0\n",
    "target_committees = 3\n",
    "\n",
    "for committee in committees:\n",
    "    if committees_processed >= target_committees:\n",
    "        break\n",
    "\n",
    "    print(f\"\\n{committees_processed + 1}. Checking: {committee['committee_name']}\")\n",
    "    print(f\"   Committee ID: {committee['committee_id']}\")\n",
    "\n",
    "    # Extract contributions\n",
    "    all_contributions = []\n",
    "\n",
    "    try:\n",
    "        for page_df, metadata in schedule_a_extractor.extract_schedule_a_pages(\n",
    "            committee_id=committee['committee_id'],\n",
    "            election_cycle=2026,\n",
    "            starting_page=1\n",
    "        ):\n",
    "            # Check if committee has no data\n",
    "            if metadata['page'] == 1 and metadata['total_count'] == 0:\n",
    "                print(f\"   ⊘ No contributions found, skipping...\")\n",
    "                break\n",
    "\n",
    "            all_contributions.append(page_df)\n",
    "\n",
    "            # Show progress every 5 pages\n",
    "            if metadata['page'] % 5 == 0 or metadata['page'] == 1:\n",
    "                print(f\"   Page {metadata['page']}/{metadata['total_pages']}: \"\n",
    "                      f\"{sum(len(df) for df in all_contributions)} records so far...\")\n",
    "\n",
    "            # Limit to first 500 records per committee for testing\n",
    "            if sum(len(df) for df in all_contributions) >= 500:\n",
    "                print(f\"   Reached 500 record limit\")\n",
    "                break\n",
    "\n",
    "        if all_contributions:\n",
    "            # Combine all pages\n",
    "            contributions_df = pd.concat(all_contributions, ignore_index=True)\n",
    "            print(f\"   ✓ Extracted {len(contributions_df)} contributions\")\n",
    "\n",
    "            # Load to bronze\n",
    "            with get_db_session() as session:\n",
    "                loaded = schedule_a_loader.load(session, contributions_df)\n",
    "                total_loaded += loaded\n",
    "                print(f\"   ✓ Loaded {loaded} contributions to bronze_fec_schedule_a\")\n",
    "\n",
    "            committees_processed += 1\n",
    "        else:\n",
    "            print(f\"   ⊘ No contributions, skipping...\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"   ✗ Error: {e}\")\n",
    "        continue\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"TOTAL: Loaded {total_loaded} contributions from {committees_processed} committees\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Verify Bronze Layer Population (run this again)\n",
    "print(\"=\"*60)\n",
    "print(\"BRONZE LAYER SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "with get_db_session() as session:\n",
    "    from fund_lens_etl.models.bronze.fec import (\n",
    "        BronzeFECCommittee,\n",
    "        BronzeFECCandidate,\n",
    "        BronzeFECScheduleA,\n",
    "    )\n",
    "    from sqlalchemy import select, func\n",
    "\n",
    "    # Count records\n",
    "    committee_count = session.execute(\n",
    "        select(func.count()).select_from(BronzeFECCommittee)\n",
    "    ).scalar()\n",
    "\n",
    "    candidate_count = session.execute(\n",
    "        select(func.count()).select_from(BronzeFECCandidate)\n",
    "    ).scalar()\n",
    "\n",
    "    contribution_count = session.execute(\n",
    "        select(func.count()).select_from(BronzeFECScheduleA)\n",
    "    ).scalar()\n",
    "\n",
    "    print(f\"\\n✓ Bronze Layer Populated:\")\n",
    "    print(f\"  Committees:    {committee_count:,}\")\n",
    "    print(f\"  Candidates:    {candidate_count:,}\")\n",
    "    print(f\"  Contributions: {contribution_count:,}\")\n",
    "\n",
    "    # Show which committees have contributions\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"Contributions by Committee:\")\n",
    "\n",
    "    result = session.execute(\n",
    "        select(\n",
    "            BronzeFECScheduleA.committee_id,\n",
    "            func.count(BronzeFECScheduleA.sub_id).label('count')\n",
    "        )\n",
    "        .group_by(BronzeFECScheduleA.committee_id)\n",
    "        .order_by(func.count(BronzeFECScheduleA.sub_id).desc())\n",
    "    )\n",
    "\n",
    "    for row in result:\n",
    "        committee = session.execute(\n",
    "            select(BronzeFECCommittee.name)\n",
    "            .where(BronzeFECCommittee.committee_id == row.committee_id)\n",
    "        ).scalar_one_or_none()\n",
    "\n",
    "        print(f\"  {row.committee_id}: {row.count:,} contributions\")\n",
    "        if committee:\n",
    "            print(f\"    ({committee})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagnostic: Check if duplicates were from API or database\n",
    "print(\"=\"*60)\n",
    "print(\"DIAGNOSTIC: Source of Duplicates\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Re-extract one page from ALSOBROOKS without loading\n",
    "test_df = None\n",
    "for page_df, metadata in schedule_a_extractor.extract_schedule_a_pages(\n",
    "    committee_id=\"C00840017\",  # ALSOBROOKS\n",
    "    election_cycle=2026,\n",
    "    starting_page=1\n",
    "):\n",
    "    test_df = page_df\n",
    "    break\n",
    "\n",
    "if test_df is not None:\n",
    "    print(f\"One page extracted: {len(test_df)} records\")\n",
    "\n",
    "    # Check for duplicates in the raw page\n",
    "    duplicates_in_page = test_df['sub_id'].duplicated().sum()\n",
    "    print(f\"Duplicates within this single page: {duplicates_in_page}\")\n",
    "\n",
    "    # Check unique sub_ids\n",
    "    unique_count = test_df['sub_id'].nunique()\n",
    "    print(f\"Unique sub_ids in page: {unique_count}\")\n",
    "\n",
    "    # Check what's already in database\n",
    "    with get_db_session() as session:\n",
    "        from fund_lens_etl.models.bronze.fec import BronzeFECScheduleA\n",
    "        from sqlalchemy import select\n",
    "\n",
    "        existing_sub_ids = list(test_df['sub_id'].head(10))\n",
    "\n",
    "        result = session.execute(\n",
    "            select(BronzeFECScheduleA.sub_id)\n",
    "            .where(BronzeFECScheduleA.sub_id.in_(existing_sub_ids))\n",
    "        )\n",
    "\n",
    "        db_sub_ids = [row[0] for row in result]\n",
    "\n",
    "        print(f\"\\nChecking first 10 sub_ids from extracted page:\")\n",
    "        print(f\"  Already in database: {len(db_sub_ids)}/10\")\n",
    "\n",
    "        if len(db_sub_ids) > 0:\n",
    "            print(f\"\\n  ✓ Duplicates were from EXISTING database records (UPSERT working correctly)\")\n",
    "        else:\n",
    "            print(f\"\\n  ✗ No existing records found - duplicates were from API\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
